name: Cron Build

on:
  schedule:
    - cron: '12 7 * * *'

env:
  CI: true
  SCRAPY_SETTINGS_MODULE: city_scrapers.settings.prod
  WAYBACK_ENABLED: true
  AUTOTHROTTLE_MAX_DELAY: 30.0
  AUTOTHROTTLE_START_DELAY: 1.5
  AUTOTHROTTLE_TARGET_CONCURRENCY: 3.0
  AZURE_ACCOUNT_KEY: ${{ secrets.AZURE_ACCOUNT_KEY }}
  AZURE_ACCOUNT_NAME: ${{ secrets.AZURE_ACCOUNT_NAME }}
  AZURE_CONTAINER: ${{ secrets.AZURE_CONTAINER }}
  AZURE_STATUS_CONTAINER: ${{ secrets.AZURE_STATUS_CONTAINER }}

jobs:
  crawl:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v1
    - name: Set up Python 3.7
      uses: actions/setup-python@v1
      with:
        python-version: 3.7
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Run scrapers
      run: |
        export PYTHONPATH=$(pwd):$PYTHONPATH
        ./.deploy.sh
    - name: Combine output feeds
      run: |
        export PYTHONPATH=$(pwd):$PYTHONPATH
        scrapy combinefeeds -s LOG_ENABLED=False
