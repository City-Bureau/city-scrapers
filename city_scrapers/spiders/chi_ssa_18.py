import re
from datetime import datetime

from city_scrapers_core.constants import COMMISSION
from city_scrapers_core.items import Meeting
from city_scrapers_core.spiders import CityScrapersSpider
from scrapy import Selector


class ChiSsa18Spider(CityScrapersSpider):
    name = "chi_ssa_18"
    agency = "Chicago Special Service Area #18 North Halsted"
    timezone = "America/Chicago"
    start_urls = ["https://northalsted.com/community/"]
    location = {
        "name": "Center on Halsted",
        "address": "3656 N Halsted St, Conference Room 200, Chicago IL 60613",
    }

    def parse(self, response):
        """
        `parse` should always `yield` Meeting items.

        Change the `_parse_title`, `_parse_start`, etc methods to fit your scraping
        needs.
        """
        table = response.xpath(
            '//*[@id="page_content_wrapper"]/div/div/div/div[1]/div[3]'
        )

        self._validate_location(table)
        self._validate_meeting_times(table)

        for item in table.xpath(".//h3 | .//p"):
            if "h3" in item.get():
                meeting_year = None
                meeting_year = item.xpath("descendant-or-self::text()").re_first(
                    r"\d{4}"
                )
                continue
            if "<p>" in item.get():
                split_items = [
                    Selector(text=section) for section in re.split(r"<br>", item.get())
                ]
                for split_string in split_items:
                    meeting_date_match = split_string.re_first(r"([A-Z]\w{2,}\s\d\d?)")
                    if not (meeting_date_match and meeting_year):
                        continue
                    converted_date = self._convert_date(
                        meeting_date_match, meeting_year
                    )

                    meeting = Meeting(
                        title="Commission",
                        description="",
                        classification=COMMISSION,
                        start=self._parse_start(converted_date),
                        end=self._parse_end(converted_date),
                        all_day=self._parse_all_day(item),
                        time_notes="",
                        location=self.location,
                        links=self._parse_links(split_string),
                        source=self._parse_source(response),
                    )

                    meeting["status"] = self._get_status(meeting)
                    meeting["id"] = self._get_id(meeting)

                    yield meeting

    def _validate_location(self, item):
        location_test = item.get()
        if "3656 N Halsted" not in location_test:
            raise ValueError("Meeting location has changed")
        elif "Conference Room 200" not in location_test:
            raise ValueError("Meeting location has changed")

    def _validate_meeting_times(self, item):
        meeting_time = item.get()
        if "9:00 am â€“ 10:30 am" not in meeting_time:
            raise ValueError("Meeting time has changed")

    def _convert_date(self, meeting_date, meeting_year):
        split_date = meeting_date.split(" ")
        day = split_date[1]
        month = split_date[0]
        year = meeting_year
        converted_date = datetime.strptime(month + day + year, "%B%d%Y")
        return converted_date

    def _parse_start(self, item):
        """Parse start datetime as a naive datetime object."""
        return item.replace(hour=9)

    def _parse_end(self, item):
        """Parse end datetime as a naive datetime object. Added by pipeline if None"""
        return item.replace(hour=10, minute=30)

    def _parse_time_notes(self, item):
        """Parse any additional notes on the timing of the meeting"""
        return ""

    def _parse_all_day(self, item):
        """Parse or generate all-day status. Defaults to False."""
        return False

    def _parse_links(self, item):
        """Parse or generate links."""
        parsed_links = []
        for links in item.xpath(".//a"):
            parsed_links.append(
                {
                    "href": links.xpath("@href").get(),
                    "title": links.xpath("text()").get(),
                }
            )
        return parsed_links

    def _parse_source(self, response):
        """Parse or generate source."""
        return response.url
